{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85832aba",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e06cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import math\n",
    "import datetime\n",
    "from sklearn import linear_model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, f1_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46881cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5d058",
   "metadata": {},
   "source": [
    "## Scrapping the top 100 hot songs from billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb8e82",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%writefile -a functions.py\n",
    "def scrape_hot100():\n",
    "   \n",
    "    url = \"https://www.billboard.com/charts/hot-100/\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser') \n",
    "    titles = []\n",
    "    artists = []\n",
    "    for index, elem in enumerate(soup.find_all(\"li\",{\"class\":\"lrv-u-width-100p\"})):\n",
    "        if ( index%2 == 0 ):\n",
    "            titles.append(elem.find_all(\"h3\")[0].get_text().replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n",
    "            artists.append(elem.select(\"span\")[0].get_text().replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n",
    "    billboard100=pd.DataFrame({\"title\":titles, \"artist\": artists})\n",
    "    return billboard100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df25cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_hot100()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc103f5",
   "metadata": {},
   "source": [
    "## Adding a database for not hot songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Spotify-2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209696f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_hot_songs = data[['Title', 'Artist']]\n",
    "not_hot_songs.rename(columns = {'Title':'title','Artist':'artist'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_hot_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cef0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_hot_songs.to_csv('not_hot_songs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62621fd",
   "metadata": {},
   "source": [
    "## Creating search_song()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6de120",
   "metadata": {},
   "source": [
    "Create a function to search a given song in the Spotify API: search_song(). Take into account that sometimes Spotify's API will return several matches for the same song title (different artists, a different album of the same artist, version of the song,...etc). Then it will be nice to display a list of outputs to the user and let him/her select which is the right match. Once the desired song is located, the function should return the href/id/uri of the song to the code (not to the user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ee1179",
   "metadata": {},
   "source": [
    "## Creating \"get_audio_features(list_of_songs)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184189d8",
   "metadata": {},
   "source": [
    "Create a function \"get_audio_features(list_of_songs)\" to obtain the audio features of a given list of songs (the content of list_of_songs can be the href/id/uri). Then, use this function to create a Pandas Dataframe with the audio features of the list of songs. Hint: create a dictionary with the song's audio features as keys and an empty list as values. Then fill in the lists with the corresponding audio features of each song. Finally, create your data frame from the dictionary. Bear in mind the following: This API has a restriction on the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d1406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cffc247",
   "metadata": {},
   "source": [
    "## Creating \"add_audio_features(df, audio_features_df)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f9d270",
   "metadata": {},
   "source": [
    "Once the previous function has been created, create another function \"add_audio_features(df, audio_features_df)\" to concat a given data frame with the data frame containing the audio features alongside any other desired info, and return the extended data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5e560",
   "metadata": {},
   "source": [
    "Replace the old internal files of songs (hot and not hot) with the extended data frames with the audio features and save them into separate files on the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78781fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59169085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68037195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114209a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce67881a",
   "metadata": {},
   "source": [
    "## Clustering the songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fb681",
   "metadata": {},
   "source": [
    "Now it's time to cluster the songs of the hot_songs and not_hot_songs databases according to the song's audio features. You will need to consider the following:\n",
    "\n",
    "Are you going to use all the audio features? If not, which ones do you think to make more sense?\n",
    "What is the optimal number of clusters (for methods that need to know this beforehand)?\n",
    "What is the best distance to use?\n",
    "What clustering method provides better results?\n",
    "Does the clustering method need a transformer?\n",
    "Be aware that this process is extremely time-consuming!!! Therefore, when testing different options, save the models into your disk in order to be able to use the best model later.  You don't want to retrain the best model again when you know what are the optimal parameters for each.\n",
    "\n",
    "Add to the hot_songs and not_hot_songs databases a new column for each clustering method with the cluster membership of each song for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69998c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2affb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
